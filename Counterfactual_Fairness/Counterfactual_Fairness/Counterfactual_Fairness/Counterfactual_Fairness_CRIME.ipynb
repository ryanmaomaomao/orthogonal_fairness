{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fairml-research/Counterfactual_Fairness/blob/main/Counterfactual_Fairness_CRIME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0a659283",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-09T17:15:41.033876Z",
          "start_time": "2024-01-09T17:15:40.973025Z"
        },
        "id": "0a659283"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/fairml-research/Counterfactual_Fairness.git\"\n",
        "import sys, os\n",
        "os.chdir('Counterfactual_Fairness')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmE2o4fnsHHj",
        "outputId": "921c7a90-abad-460a-9dd9-f9dd28de494d"
      },
      "id": "TmE2o4fnsHHj",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Counterfactual_Fairness'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 20 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (20/20), 10.65 KiB | 3.55 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5245d46d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-09T17:15:41.800508Z",
          "start_time": "2024-01-09T17:15:41.775737Z"
        },
        "id": "5245d46d"
      },
      "outputs": [],
      "source": [
        "from models.functions import *\n",
        "from models.adv_vae import ADV_VAE\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) **IMPORT THE DATA**"
      ],
      "metadata": {
        "id": "h2IRVI24QQ7m"
      },
      "id": "h2IRVI24QQ7m"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2b4e5b21",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-09T17:15:42.934042Z",
          "start_time": "2024-01-09T17:15:42.817974Z"
        },
        "id": "2b4e5b21"
      },
      "outputs": [],
      "source": [
        "from data_loading.datasets import read_dataset\n",
        "\n",
        "# split into train/test set\n",
        "#X_train, X_test, y_train, y_test, sensitive, sensitivet = train_test_split(X, y, Z, test_size=0.1, random_state=4)\n",
        "\n",
        "X_train, y_train, sensitive, X_test, y_test, sensitivet = read_dataset(name='crimes', fold=1)\n",
        "X_train, y_train, Z_train, X_test, y_test, Z_test, scaler, scale_df, meanYtrain, stdYtrain= Normalize(X_train, y_train, sensitive, X_test, y_test, sensitivet)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) ADVERSARIAL INFERENCE\n",
        "\n",
        "a) In this part we are going to train a latent space z from X_train, y_train and the sensitive and we will try to recontruct X and Y from the latent space z and the sensitive. In addtion to that there is an adversarial model for mitigating the dependance with the sensitive attribute.\n",
        "\n",
        "b) In this scenario we have X that is between 0 and 1. Please note that if you want to adapt X for a continuous scenario you need to change this:\n",
        " - line 103 in adv_vae.py replace the BCE loss with an MSE one (F.binary_cross_entropy -> F.mse_loss)\n",
        " - line 129 in functions.py remove the sigmoid -> (torch.sigmoid(self.fc41(h3)) -> self.fc41(h3)\n",
        "\n",
        "c) You can see that the betaadv hyerparameter allows to mitigate the dependance with the sensitive (assessed with the HGR at the end of this senction 2). If betaadv =0 the HGR is superior to 0.9 !! and with a lambdaadv it is closer to 0.5"
      ],
      "metadata": {
        "id": "ZaAW6Sn2QawP"
      },
      "id": "ZaAW6Sn2QawP"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2e2a7b08",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-09T17:16:12.372433Z",
          "start_time": "2024-01-09T17:15:48.240519Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e2a7b08",
        "outputId": "798f5a77-ea6b-4f21-c79f-54080682fb9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:   1%|          | 1/101 [00:02<04:43,  2.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 1.0004787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:   6%|▌         | 6/101 [00:04<00:41,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.9497099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  11%|█         | 11/101 [00:05<00:28,  3.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.92258453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  16%|█▌        | 16/101 [00:07<00:28,  3.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.890488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  21%|██        | 21/101 [00:10<00:42,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.85391927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  26%|██▌       | 26/101 [00:12<00:29,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.8173647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  31%|███       | 31/101 [00:13<00:21,  3.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.7819688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  36%|███▌      | 36/101 [00:15<00:18,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.7352442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  41%|████      | 41/101 [00:16<00:17,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.70688385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  46%|████▌     | 46/101 [00:18<00:16,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.67116755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  50%|█████     | 51/101 [00:19<00:14,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.6410544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  55%|█████▌    | 56/101 [00:21<00:15,  2.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.6112641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  60%|██████    | 61/101 [00:22<00:12,  3.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.5874788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  65%|██████▌   | 66/101 [00:24<00:10,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.5394028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  70%|███████   | 71/101 [00:25<00:08,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.48182377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  75%|███████▌  | 76/101 [00:27<00:07,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.40964538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  80%|████████  | 81/101 [00:28<00:05,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.21545309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  85%|████████▌ | 86/101 [00:30<00:04,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.15752783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  90%|█████████ | 91/101 [00:31<00:02,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.1373161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  95%|█████████▌| 96/101 [00:33<00:01,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.096603304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc: 100%|██████████| 101/101 [00:35<00:00,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_Y 0.10574269\n",
            "Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "sizelat=5\n",
        "class Adversarial(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Adversarial, self).__init__()\n",
        "        self.adv_fc1 = nn.Linear(sizelat, 32)\n",
        "        self.adv_fc2 = nn.Linear(32, 16)\n",
        "        self.adv_fc3 = nn.Linear(16, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.adv_fc1(x)\n",
        "        x = F.tanh(x)\n",
        "        #x = F.dropout(x, p=0.8)\n",
        "        x = self.adv_fc2(x)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, p=0.8)\n",
        "        x = self.adv_fc3(x)\n",
        "        #x = torch.sigmoid(x)\n",
        "        return x\n",
        "from models.adv_vae import ADV_VAE\n",
        "#modelVAE=VAE(X_train.shape[1])\n",
        "from tqdm import trange\n",
        "\n",
        "batch_size=512\n",
        "epochs=100\n",
        "seed=1\n",
        "log_interval=1\n",
        "betaX = 1\n",
        "betaY = 1\n",
        "#betaKLD = 10\n",
        "betammd_E =1#1\n",
        "#betammd_F =0\n",
        "betaadv=100 #.1\n",
        "#device=\"cpu\"\n",
        "device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from tqdm import trange\n",
        "import argparse\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable\n",
        "from models.functions import VAE\n",
        "modelVAE=VAE(X_train.shape[1])\n",
        "\n",
        "ADV_VAE_S0 = ADV_VAE(batch_size, epochs, seed, log_interval, device, nb_features =X_train.shape[1],\n",
        "                     model = modelVAE, model_adv = Adversarial, sizelat=sizelat,\n",
        "                     betaX=betaX,betaY=betaY,betammd_E=betammd_E,betaadv=betaadv\n",
        "                    )\n",
        "ADV_VAE_S0.fit(X_train, y_train, Z_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c57c0d26",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-09T17:19:59.287178Z",
          "start_time": "2024-01-09T17:19:59.006803Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c57c0d26",
        "outputId": "ee41be4c-55d1-49d3-ea58-05f7f094db5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_X TEST 0.51497513 Loss_Y TEST 0.10599426\n",
            "HGR NN Test 0.57030624\n"
          ]
        }
      ],
      "source": [
        "from models.functions import HGR_NN\n",
        "senstest=torch.tensor(np.expand_dims(Z_test,axis = 1)).float().to(device)\n",
        "datatest=torch.tensor(X_test.values).float().to(device)\n",
        "ydatatest= Variable(torch.FloatTensor(np.expand_dims(y_test,axis = 1))).to(device)\n",
        "recon_X, z, recon_Y, mu, logvar = ADV_VAE_S0.predict(datatest.view(-1, datatest.shape[1]),senstest,ydatatest)\n",
        "Loss_X = F.binary_cross_entropy(recon_X, datatest.view(-1, datatest.shape[1]), reduction='mean')\n",
        "Loss_Y = F.mse_loss(recon_Y, ydatatest, reduction='mean')\n",
        "print(\"Loss_X TEST\", Loss_X.cpu().detach().numpy(), \"Loss_Y TEST\",Loss_Y.cpu().detach().numpy())\n",
        "# lambda = 0\n",
        "HGR_NNP = HGR_NN(Net_HGR(),Net2_HGR(),device, display=False)\n",
        "print(\"HGR NN Test\",HGR_NNP(senstest , z,200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7f6df566",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-09T17:20:01.773095Z",
          "start_time": "2024-01-09T17:20:01.469250Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f6df566",
        "outputId": "4dd709a9-7939-47fa-a3ee-760cfa890fcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss_X 0.50609195 Loss_Y 0.10484505\n",
            "HGR NN Train 0.27441216\n"
          ]
        }
      ],
      "source": [
        "from models.functions import HGR_NN\n",
        "senstrain=torch.tensor(np.expand_dims(Z_train,axis = 1)).float().to(device)\n",
        "data=torch.tensor(X_train.values).float().to(device)\n",
        "ydata= Variable(torch.FloatTensor(np.expand_dims(y_train,axis = 1))).to(device)\n",
        "recon_X, z, recon_Y, mu, logvar = ADV_VAE_S0.predict(data.view(-1, data.shape[1]),senstrain,ydata)\n",
        "Loss_X = F.binary_cross_entropy(recon_X, data.view(-1, data.shape[1]), reduction='mean')\n",
        "Loss_Y = F.mse_loss(recon_Y, ydata, reduction='mean')\n",
        "print(\"Loss_X\", Loss_X.cpu().detach().numpy(), \"Loss_Y\",Loss_Y.cpu().detach().numpy() )\n",
        "# lambda = 0\n",
        "HGR_NNP = HGR_NN(Net_HGR(),Net2_HGR(),device, display=False)\n",
        "print(\"HGR NN Train\",HGR_NNP(senstrain , z,200))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) **Unfair Predictor Model** (lambdap=0)\n",
        "\n",
        "In this second part we are now going to create a predictor model that is counterfactual \" UnFair \" --> the lambdap of penalization is equal to 0 !\n",
        "\n",
        "Please note that in the third part we are going to make the predictor model Fairer."
      ],
      "metadata": {
        "id": "VRyDb_nJS0th"
      },
      "id": "VRyDb_nJS0th"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ae52e485",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-09T17:20:49.861000Z",
          "start_time": "2024-01-09T17:20:04.754188Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae52e485",
        "outputId": "117d4599-a1f9-489a-d08d-2f51b558dff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:   0%|          | 4/1001 [00:00<00:55, 17.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 1.2260033 conterfactual estimation : 1.9581312e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  10%|█         | 102/1001 [00:06<01:09, 12.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.31259534 conterfactual estimation : 0.32656652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  20%|██        | 204/1001 [00:13<00:48, 16.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.31692034 conterfactual estimation : 0.5039541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  30%|███       | 304/1001 [00:19<00:38, 18.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.22404101 conterfactual estimation : 0.39259952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  40%|████      | 404/1001 [00:25<00:39, 15.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.21040821 conterfactual estimation : 0.4358147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  50%|█████     | 504/1001 [00:31<00:28, 17.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.2247378 conterfactual estimation : 0.4126508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  60%|██████    | 603/1001 [00:38<00:41,  9.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.19057909 conterfactual estimation : 0.6366669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  70%|███████   | 703/1001 [00:44<00:17, 16.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.1873219 conterfactual estimation : 0.47078758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  80%|████████  | 803/1001 [00:50<00:15, 13.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.25653195 conterfactual estimation : 0.57096213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  90%|█████████ | 903/1001 [00:56<00:05, 16.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.20654169 conterfactual estimation : 0.5464819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc: 100%|██████████| 1001/1001 [01:03<00:00, 15.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.23729421 conterfactual estimation : 0.49004087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from models.cf_predictor import CF_PREDICTOR\n",
        "\n",
        "\n",
        "#device = torch.device(\"cpu\")\n",
        "#device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1]+1, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 16)\n",
        "        self.fc4 = nn.Linear(16, 1)\n",
        "    def forward(self, x, a):\n",
        "        x = self.fc1(torch.cat([x,a],1))\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "batch_idx=0\n",
        "batch_size=256\n",
        "epochs=1000\n",
        "seed=1\n",
        "log_interval=1\n",
        "lr=0.0001\n",
        "nb=20\n",
        "lambdap=0.\n",
        "CF_PREDICTOR_S0 = CF_PREDICTOR(regressor=\"mse\",batch_size=batch_size, epochs=epochs, seed=seed, log_interval=log_interval, device=device, model = NN, lr=lr, modelVAE= ADV_VAE_S0, nb=nb, lambdap=lambdap)\n",
        "CF_PREDICTOR_S0.fit(X_train, y_train, Z_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "44ac1224",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-09T17:20:54.199727Z",
          "start_time": "2024-01-09T17:20:54.172455Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44ac1224",
        "outputId": "abd159b6-e4c0-4220-ef1e-4b7c84e99005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE TEST: 0.38039482\n"
          ]
        }
      ],
      "source": [
        "senstest=torch.tensor(np.expand_dims(Z_test,axis = 1)).float().to(device)\n",
        "datatest=torch.tensor(X_test.values).float().to(device)\n",
        "ydatatest= Variable(torch.FloatTensor(np.expand_dims(y_test,axis = 1))).to(device)\n",
        "\n",
        "Yhat_test=CF_PREDICTOR_S0.predict(datatest,senstest)\n",
        "MSE_Test = F.mse_loss(Yhat_test,ydatatest)\n",
        "print(\"MSE TEST:\",MSE_Test.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "06eac11e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-09T17:20:55.089601Z",
          "start_time": "2024-01-09T17:20:54.870422Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06eac11e",
        "outputId": "a3575d75-8451-492c-9393-cb0635cf544e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CF Value:   0.703899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-8ffb242bdcb1>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Unif_X = torch.tensor(torch.tensor(np.expand_dims(Uni,axis=1)).repeat( X_test.shape[0],1), dtype=torch.float32).to(device)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "nb = 1000\n",
        "Uni = np.random.uniform(Z_train.min(),Z_train.max(),nb)\n",
        "#Unif_X = torch.tensor(np.random.uniform(Z_train.min(),Z_train.max(),Z_test.shape[0]*nb), dtype=torch.float32).to(device)\n",
        "Unif_X = torch.tensor(torch.tensor(np.expand_dims(Uni,axis=1)).repeat( X_test.shape[0],1), dtype=torch.float32).to(device)\n",
        "data_X = torch.tensor(np.repeat(X_test.values, nb,0), dtype=torch.float32).to(device)\n",
        "Y_X    = torch.tensor(np.repeat(y_test.values, nb,0), dtype=torch.float32).to(device)\n",
        "recon_X_aprime, z_aprime, recon_Y_aprime, mu_aprime, logvar_aprime = ADV_VAE_S0(data_X.view(-1, data_X.shape[1]),Unif_X,Y_X)\n",
        "Z_train_X = torch.tensor(np.repeat(Z_test.values, nb,0), dtype=torch.float32).to(device)\n",
        "recon_X_a, z_a, recon_Y_a, mu_a, logvar_a = ADV_VAE_S0.predict(data_X, Z_train_X , Y_X)\n",
        "\n",
        "predY_a_prime = CF_PREDICTOR_S0.predict(recon_X_aprime,Unif_X).cpu().detach().numpy()\n",
        "predY_a = CF_PREDICTOR_S0.predict(recon_X_a,Z_train_X.unsqueeze(1)).cpu().detach().numpy()\n",
        "print('CF Value:  {:9f}'.format(np.mean((predY_a_prime-predY_a)**2),8))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For calculating the CF we generate 1000 possible counterfactual observations for each instance of X_test. For this, we repeat the X instances for each counterfactual and aggrate with a mean average loss.\n",
        "We observe in this scenario that the CF is pretty unfair .. we will try to mitigate this in the third part"
      ],
      "metadata": {
        "id": "gTLzwGi0TQIj"
      },
      "id": "gTLzwGi0TQIj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) **Fair Predictor Model** (lambdap=1)\n",
        "\n",
        "In this third part we are now going to create a predictor model that is counterfactual Fair.  At each batch and for each instance, we will generate 20 counterfactual observations (nb=20) from the inference model (from the step 1)"
      ],
      "metadata": {
        "id": "lRp86zDCTFp-"
      },
      "id": "lRp86zDCTFp-"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "0a4a789a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a4a789a",
        "outputId": "f3a7f05e-33b4-490f-caa3-3b60d3586f4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:   0%|          | 4/1001 [00:00<01:04, 15.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.9321294 conterfactual estimation : 4.1591815e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  10%|█         | 104/1001 [00:06<00:53, 16.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.3252374 conterfactual estimation : 0.027247746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  20%|██        | 204/1001 [00:12<00:46, 17.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.31154898 conterfactual estimation : 0.014422493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  30%|███       | 304/1001 [00:19<00:42, 16.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.3119887 conterfactual estimation : 0.011616247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  40%|████      | 404/1001 [00:25<00:34, 17.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.21687016 conterfactual estimation : 0.010118387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  50%|█████     | 504/1001 [00:32<00:28, 17.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.29507166 conterfactual estimation : 0.008266589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  60%|██████    | 604/1001 [00:37<00:21, 18.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.2817868 conterfactual estimation : 0.0061024018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  70%|███████   | 704/1001 [00:44<00:17, 17.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.23859116 conterfactual estimation : 0.0055688284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  80%|████████  | 804/1001 [00:50<00:11, 16.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.1791245 conterfactual estimation : 0.0050879666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc:  90%|█████████ | 904/1001 [00:56<00:05, 17.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.22165921 conterfactual estimation : 0.0042373636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc: 100%|██████████| 1001/1001 [01:02<00:00, 16.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE estimation : 0.20582287 conterfactual estimation : 0.003362126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from models.cf_predictor import CF_PREDICTOR\n",
        "\n",
        "#device = torch.device(\"cpu\")\n",
        "#device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1]+1, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 16)\n",
        "        self.fc4 = nn.Linear(16, 1)\n",
        "    def forward(self, x, a):\n",
        "        x = self.fc1(torch.cat([x,a],1))\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "batch_idx=0\n",
        "batch_size=256\n",
        "epochs=1000\n",
        "seed=1\n",
        "log_interval=1\n",
        "lr=0.0001\n",
        "nb=20\n",
        "lambdap=1.\n",
        "CF_PREDICTOR_S0 = CF_PREDICTOR(regressor=\"mse\",batch_size=batch_size, epochs=epochs, seed=seed, log_interval=log_interval, device=device, model = NN, lr=lr, modelVAE= ADV_VAE_S0, nb=nb, lambdap=lambdap)\n",
        "CF_PREDICTOR_S0.fit(X_train, y_train, Z_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "senstest=torch.tensor(np.expand_dims(Z_test,axis = 1)).float().to(device)\n",
        "datatest=torch.tensor(X_test.values).float().to(device)\n",
        "ydatatest= Variable(torch.FloatTensor(np.expand_dims(y_test,axis = 1))).to(device)\n",
        "\n",
        "Yhat_test=CF_PREDICTOR_S0.predict(datatest,senstest)\n",
        "MSE_Test = F.mse_loss(Yhat_test,ydatatest)\n",
        "print(\"MSE TEST:\",MSE_Test.cpu().detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GndCq9JHTNXB",
        "outputId": "f6e81ac1-4ed7-4d22-bc4b-21a7a32732d4"
      },
      "id": "GndCq9JHTNXB",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE TEST: 0.40139252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "nb = 1000\n",
        "Uni = np.random.uniform(Z_train.min(),Z_train.max(),nb)\n",
        "#Unif_X = torch.tensor(np.random.uniform(Z_train.min(),Z_train.max(),Z_test.shape[0]*nb), dtype=torch.float32).to(device)\n",
        "Unif_X = torch.tensor(torch.tensor(np.expand_dims(Uni,axis=1)).repeat( X_test.shape[0],1), dtype=torch.float32).to(device)\n",
        "data_X = torch.tensor(np.repeat(X_test.values, nb,0), dtype=torch.float32).to(device)\n",
        "Y_X    = torch.tensor(np.repeat(y_test.values, nb,0), dtype=torch.float32).to(device)\n",
        "recon_X_aprime, z_aprime, recon_Y_aprime, mu_aprime, logvar_aprime = ADV_VAE_S0(data_X.view(-1, data_X.shape[1]),Unif_X,Y_X)\n",
        "Z_train_X = torch.tensor(np.repeat(Z_test.values, nb,0), dtype=torch.float32).to(device)\n",
        "recon_X_a, z_a, recon_Y_a, mu_a, logvar_a = ADV_VAE_S0.predict(data_X, Z_train_X , Y_X)\n",
        "\n",
        "predY_a_prime = CF_PREDICTOR_S0.predict(recon_X_aprime,Unif_X).cpu().detach().numpy()\n",
        "predY_a = CF_PREDICTOR_S0.predict(recon_X_a,Z_train_X.unsqueeze(1)).cpu().detach().numpy()\n",
        "print('CF Value:  {:9f}'.format(np.mean((predY_a_prime-predY_a)**2),8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcP6j9QiTPQM",
        "outputId": "38b10a9b-07bd-4fbd-c449-2b5c818248ea"
      },
      "id": "wcP6j9QiTPQM",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CF Value:   0.003216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-8ffb242bdcb1>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Unif_X = torch.tensor(torch.tensor(np.expand_dims(Uni,axis=1)).repeat( X_test.shape[0],1), dtype=torch.float32).to(device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-UGnJuEpT_mq"
      },
      "id": "-UGnJuEpT_mq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:Transf] *",
      "language": "python",
      "name": "conda-env-Transf-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}